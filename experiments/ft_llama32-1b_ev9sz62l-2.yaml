# https://wandb.ai/rshwndsz/odysseus/runs/7cd51xpn

model_id: "meta-llama/Llama-3.2-1B-Instruct"

dynamic_padding: True
max_length: 8196
quantization_bits: 8

lora_r: 8
lora_alpha: 64
lora_dropout: 0.005566378209182984

num_epochs: 8
batch_size: 4
gradient_accumulation_steps: 2

learning_rate: 0.00000175688634632561
weight_decay: 0.026447791101207093
lr_scheduler_type: "cosine_with_restarts"
